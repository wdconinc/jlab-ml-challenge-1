{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wdconinc/jlab-ml-challenge-1/blob/master/train_gutted.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6BalCEpUtMq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building on toy3 example, this adds drift distance\n",
        "# information to the pixel color. It also adds a \n",
        "# random z-vertex position in addition to the phi\n",
        "# angle. \n",
        "#\n",
        "# The network is defined with 2 branches to calculate\n",
        "# the phi and z. They share a common input layer and\n",
        "# initial Dense layer then implement their own dense\n",
        "# layers.\n",
        "#\n",
        "# Another difference from toy3 is that a final dense\n",
        "# layer with a single neuron is added to each of the\n",
        "# branches to calculate phi(z) parameters directly\n",
        "# rather than doing that outside of the network. To\n",
        "# help this, the weights feeding that last neuron are\n",
        "# set to fixed weights (bin centers) and are marked\n",
        "# as non-trainable.\n",
        "#\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "# If running on Google Colaboratory you can uncomment the\n",
        "# following and modify to use your Google Drive space.\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "#workdir = '/content/gdrive/My Drive/work/2019.03.26.trackingML/eff100_inverted'\n",
        "#os.chdir( workdir )\n",
        "\n",
        "\n",
        "from keras.models import load_model\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Reshape, Flatten, Dropout, BatchNormalization, Input, Activation\n",
        "from keras.optimizers import SGD, Adamax, Adadelta\n",
        "from keras.initializers import glorot_normal\n",
        "from keras.callbacks import Callback, TensorBoard\n",
        "from keras.utils.training_utils import multi_gpu_model\n",
        "import keras.backend as K\n",
        "import keras.losses\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIe-wc9QVu1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "width  = 36\n",
        "height = 100\n",
        "EPOCHS = 1000\n",
        "BS     = 2000\n",
        "GPUS   = 0\n",
        "Nouts  = 60\n",
        "\n",
        "PHIMIN   = -12.0\n",
        "PHIMAX   =  12.0\n",
        "PHI_BINSIZE = (PHIMAX-PHIMIN)/Nouts\n",
        "\n",
        "ZMIN   = -9.0\n",
        "ZMAX   =  9.0\n",
        "Z_BINSIZE = (ZMAX-ZMIN)/Nouts\n",
        "\n",
        "# Open labels files so we can get number of samples and pass the\n",
        "# data frames to the generators later\n",
        "traindf = pd.read_csv('TRAIN/track_parms.csv')\n",
        "validdf = pd.read_csv('VALIDATION/track_parms.csv')\n",
        "STEP_SIZE_TRAIN = len(traindf)/BS\n",
        "STEP_SIZE_VALID = len(validdf)/BS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGfkDUgXVyW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-----------------------------------------------------\n",
        "# generate_arrays_from_file\n",
        "#-----------------------------------------------------\n",
        "# Create generator to read in images and labels\n",
        "# (used for both training and validation samples)\n",
        "def generate_arrays_from_file( path, labelsdf ):\n",
        "\n",
        "\timages_path = path+'/images.raw.gz'\n",
        "\tprint( 'generator created for: ' + images_path)\n",
        "\n",
        "\tbatch_input           = []\n",
        "\tbatch_labels_phi      = []\n",
        "\tbatch_labels_z        = []\n",
        "\tidx = 0\n",
        "\tibatch = 0\n",
        "\twhile True:  # loop forever, re-reading images from same file\n",
        "\t\twith gzip.open(images_path) as f:\n",
        "\t\t\twhile True: # loop over images in file\n",
        "\t\t\t\n",
        "\t\t\t\t# Read in one image\n",
        "\t\t\t\tbytes = f.read(width*height)\n",
        "\t\t\t\tif len(bytes) != (width*height): break # break into outer loop so we can re-open file\n",
        "\t\t\t\tdata = np.frombuffer(bytes, dtype='B', count=width*height)\n",
        "\t\t\t\tpixels = np.reshape(data, [width, height, 1], order='F')\n",
        "\t\t\t\tpixels_norm = np.transpose(pixels.astype(np.float) / 255., axes=(1, 0, 2) )\n",
        "\t\t\t\t\n",
        "\t\t\t\t# Labels\n",
        "\t\t\t\tphi = labelsdf.phi[idx]\n",
        "\t\t\t\tz   = labelsdf.z[idx]\n",
        "\t\t\t\tidx += 1\n",
        "\n",
        "\t\t\t\t# Add to batch and check if it is time to yield\n",
        "\t\t\t\tbatch_input.append( pixels_norm )\n",
        "\t\t\t\tbatch_labels_phi.append( phi )\n",
        "\t\t\t\tbatch_labels_z.append( z )\n",
        "\t\t\t\tif len(batch_input) == BS :\n",
        "\t\t\t\t\tibatch += 1\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\t# Since we are training multiple loss functions we must\n",
        "\t\t\t\t\t# pass the labels back as a dictionary whose keys match\n",
        "\t\t\t\t\t# the layer their corresponding values are being applied\n",
        "\t\t\t\t\t# to.\n",
        "\t\t\t\t\tlabels_dict = {\n",
        "\t\t\t\t\t\t'phi_output' :  np.array(batch_labels_phi ),\n",
        "\t\t\t\t\t\t'z_output'   :  np.array(batch_labels_z   ),\t\t\n",
        "\t\t\t\t\t}\n",
        "\t\t\t\t\t\n",
        "\t\t\t\t\tyield ( np.array(batch_input), labels_dict )\n",
        "\t\t\t\t\tbatch_input      = []\n",
        "\t\t\t\t\tbatch_labels_phi = []\n",
        "\t\t\t\t\tbatch_labels_z   = []\n",
        "\n",
        "\t\t\tidx = 0\n",
        "\t\t\tf.close()\n",
        "\n",
        "\n",
        "#-----------------------------------------------------\n",
        "# DefineModel\n",
        "#-----------------------------------------------------\n",
        "# This is used to define the model. It is only called if no model\n",
        "# file is found in the model_checkpoints directory.\n",
        "def DefineModel():\n",
        "\t\n",
        "\t# If GPUS==0 this will force use of CPU, even if GPUs are present\n",
        "\t# If GPUS>1 this will force the CPU to serve as orchestrator\n",
        "\t# If GPUS==1 this will do nothing, allowing GPU to act as its own orchestrator\n",
        "\tif GPUS!=1: tf.device('/cpu:0')\n",
        "\n",
        "\t# Here we build the network model.\n",
        "\t# This model is made of multiple parts. The first handles the\n",
        "\t# inputs and identifies common features. The rest are branches with\n",
        "\t# each determining an output parameter from those features.\n",
        "\tinputs      = Input(shape=(height, width, 1), name='image_inputs', )\n",
        "\toutputs     = Dense(2, activation = 'relu')(inputs)\n",
        "\tmodel = Model(input = [inputs], output = outputs)\n",
        "\n",
        "\tif GPUS<=1 :\n",
        "\t\tfinal_model = model\n",
        "\telse:\n",
        "\t\tfinal_model = multi_gpu_model( model, gpus=GPUS )\n",
        "\n",
        "\tlosses = keras.losses.mse\n",
        "\topt = keras.optimizers.adam()\n",
        "\tfinal_model.compile(loss=losses, optimizer=opt, metrics=['mae', 'mse', 'accuracy'])\n",
        "\t\n",
        "\treturn final_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I0FqXjDV0tH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = DefineModel()\n",
        "\n",
        "# Print summary of model\n",
        "model.summary()\n",
        "\n",
        "#===============================================================================\n",
        "# Create training and validation generators\n",
        "train_generator = generate_arrays_from_file('TRAIN', traindf)\n",
        "valid_generator = generate_arrays_from_file('VALIDATION', validdf)\n",
        "\n",
        "# Use tensorboard to log training. To view the training log with the\n",
        "# tensorboard gui you can run tensorboard to fire up a web server\n",
        "# so you can use your browser to view the results.\n",
        "#\n",
        "# Note: you may need to move the log file to your\n",
        "# local desktop and run tensorboard there.\n",
        "#\n",
        "#  tensorboard --logdir=./logs\n",
        "tensorboard=TensorBoard(log_dir='./logs', histogram_freq=0, batch_size=BS*GPUS, \n",
        "                        write_graph=True, write_grads=False, write_images=False, \n",
        "                        embeddings_freq=0, embeddings_layer_names=None,\n",
        "                        embeddings_metadata=None, embeddings_data=None, update_freq='epoch')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzOe2bs2Vpds",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#===============================================================================\n",
        "# Fit the model\n",
        "history = model.fit_generator(\n",
        "  generator        = train_generator\n",
        "  ,steps_per_epoch  = STEP_SIZE_TRAIN\n",
        "  ,validation_data  = valid_generator\n",
        "  ,validation_steps = STEP_SIZE_VALID\n",
        "  ,epochs=EPOCHS\n",
        "  ,use_multiprocessing=False\n",
        "  ,callbacks=[tensorboard]\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpptoqG6UzO8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://halldweb.jlab.org/talks/ML_lunch/May2019/VALIDATION/images.raw.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTSrIYWIU-lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://halldweb.jlab.org/talks/ML_lunch/May2019/VALIDATION/track_parms.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8Jlf0CT-VJiV",
        "colab": {}
      },
      "source": [
        "!mkdir VALIDATION\n",
        "!mv images.raw.gz track_parms.csv VALIDATION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoisSNywVC6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -al TRAIN\n",
        "!ls -al VALIDATION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXnkGd0hVVHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}